# Generated by Snowflake Copilot
# Import python packages
import streamlit as st
import plotly
from snowflake.snowpark.context import get_active_session
# Import required packages
import plotly.graph_objects as go
import pandas as pd

# import app pages
# from sql.org_billable_credits import org_billable_usage


from plotly.subplots import make_subplots
session = get_active_session()

def org_billable_credits():
    compute_l30_sql= """
    WITH usage_detail_rows AS
    (
    SELECT
    credits_used_compute AS credits_used_last60d,
    CASE WHEN start_time BETWEEN date_trunc('day', dateadd('day',-29,convert_timezone('UTC',current_timestamp()))) AND current_timestamp()
    THEN credits_used_compute ELSE 0 END AS credits_used_last_period,
    CASE WHEN start_time BETWEEN date_trunc('day', dateadd('day',-59,convert_timezone('UTC',current_timestamp()))) AND date_trunc('day', dateadd('day',-29,convert_timezone('UTC',current_timestamp())))
    THEN 0 ELSE credits_used_compute END AS credits_used_prior_period
    FROM HUB_DB.HUB_CONS_SC.WAREHOUSE_METERING_HISTORY_ALL
    WHERE start_time BETWEEN date_trunc('day', dateadd('day',-59,convert_timezone('UTC',current_timestamp()))) AND current_timestamp()
    )
    SELECT
    ROUND(SUM(credits_used_last_period),0) AS credits_used_last_period,
    ROUND(SUM(credits_used_prior_period),0) AS credits_used_prior_period,
    100*(SUM(credits_used_last_period) - nullif(SUM(credits_used_prior_period),0)) / (SUM(credits_used_prior_period) ) AS pct_change
    FROM usage_detail_rows
    ;"""

    storage_l30_sql = """
    WITH db_storage_usage AS (
    SELECT
    (SUM(CASE WHEN usage_date BETWEEN date_trunc('day', dateadd('day',-29,convert_timezone('UTC',current_timestamp()))) AND
    current_timestamp() THEN average_database_bytes ELSE 0 END) / POWER(2, 40) / 30) AS db_storage_used_last_period,
    (SUM(CASE WHEN usage_date BETWEEN date_trunc('day', dateadd('day',-29,convert_timezone('UTC',current_timestamp()))) AND
    current_timestamp() THEN 0 ELSE average_database_bytes END) / POWER(2, 40)/ 30) AS db_storage_used_prior_period,
    (SUM(CASE WHEN usage_date BETWEEN date_trunc('day', dateadd('day',-29,convert_timezone('UTC',current_timestamp()))) AND
    current_timestamp() THEN average_failsafe_bytes ELSE 0 END) / POWER(2, 40) / 30) AS fs_storage_used_last_period,
    (SUM(CASE WHEN usage_date BETWEEN date_trunc('day', dateadd('day',-29,convert_timezone('UTC',current_timestamp()))) AND
    current_timestamp() THEN 0 ELSE average_failsafe_bytes END) / POWER(2, 40)/ 30) AS fs_storage_used_prior_period
    FROM HUB_DB.HUB_CONS_SC.DATABASE_STORAGE_USAGE_HISTORY_ALL
    WHERE usage_date BETWEEN date_trunc('day', dateadd('day',-59,convert_timezone('UTC',current_timestamp()))) AND current_timestamp()
    ),
    stage_usage AS
    (
    SELECT
    (SUM(CASE WHEN usage_date BETWEEN date_trunc('day', dateadd('day',-29,convert_timezone('UTC',current_timestamp()))) AND
    current_timestamp() THEN average_stage_bytes ELSE 0 END) / POWER(2, 40) / 30) AS stage_storage_used_last_period,
    (SUM(CASE WHEN usage_date BETWEEN date_trunc('day', dateadd('day',-29,convert_timezone('UTC',current_timestamp()))) AND
    current_timestamp() THEN 0 ELSE average_stage_bytes END) / POWER(2, 40)/ 30) AS stage_storage_used_prior_period
    FROM HUB_DB.HUB_CONS_SC.STAGE_STORAGE_USAGE_HISTORY_ALL
    WHERE usage_date BETWEEN date_trunc('day', dateadd('day',-59,convert_timezone('UTC',current_timestamp()))) AND current_timestamp()
    )
    SELECT
    ROUND(db_storage_used_last_period + fs_storage_used_last_period + stage_storage_used_last_period,2) AS "Avg Storage Last 30 Days (TB)",
    ROUND(db_storage_used_prior_period + fs_storage_used_prior_period + stage_storage_used_prior_period,2) AS "Avg Storage Prior 30 Days
    (TB)",
    ROUND(db_storage_used_last_period,2) AS "Avg DB Storage Last 30 Days (TB)",
    ROUND(db_storage_used_prior_period,2) AS "Avg DB Storage Prior 30 Days (TB)",
    ROUND(fs_storage_used_last_period,2) AS "Avg Failsafe Storage Last 30 Days (TB)",
    ROUND(fs_storage_used_prior_period,2) AS "Avg Failsafe Storage Prior 30 Days (TB)",
    ROUND(stage_storage_used_last_period,2) AS "Avg Stage Storage Last 30 Days (TB)",
    ROUND(stage_storage_used_prior_period,2) AS "Avg Stage Storage Prior 30 Days (TB)"
    FROM db_storage_usage dsu
    LEFT JOIN stage_usage ssu -- no join columns needed
    ;"""

    compute_by_day_sql = """
    SELECT
    DATE_TRUNC('day', convert_timezone('UTC',start_time))::DATE usage_week
    ,ROUND(SUM(credits_used_compute),0) AS "Compute Credits Used"
    FROM HUB_DB.HUB_CONS_SC.WAREHOUSE_METERING_HISTORY_ALL
    WHERE start_time BETWEEN date_trunc('day', dateadd('day',-365,convert_timezone('UTC',current_timestamp()))) AND current_timestamp()
    GROUP BY 1
    ORDER BY 1;
    """    

    storage_by_day_sql = """
    WITH db_storage_usage AS (
    SELECT DATE_TRUNC('day', convert_timezone('UTC',usage_date))::DATE usage_date
    ,((sum(average_database_bytes) / POWER(2, 40)) + (sum(average_failsafe_bytes) / POWER(2, 40))) / 30 AS storage_tb
    ,(sum(average_database_bytes) / POWER(2, 40)) / 30 AS db_storage_tb
    ,(sum(average_failsafe_bytes) / POWER(2, 40)) / 30 AS failsafe_storage_tb
    FROM HUB_DB.HUB_CONS_SC.DATABASE_STORAGE_USAGE_HISTORY_ALL
    WHERE usage_date BETWEEN convert_timezone('UTC',date_trunc('week', dateadd('week',-60,current_timestamp()))) AND
    current_timestamp()
    GROUP BY 1
    ),
    stage_usage AS
    (
    SELECT DATE_TRUNC('day', convert_timezone('UTC',usage_date))::DATE usage_date
    ,(sum(average_stage_bytes) / POWER(2, 40)) / 30 AS stage_tb
    FROM snowflake.account_usage.stage_storage_usage_history
    WHERE usage_date BETWEEN convert_timezone('UTC',date_trunc('week', dateadd('week',-60,current_timestamp()))) AND
    current_timestamp()
    GROUP BY 1
    )
    SELECT dsu.usage_date AS "Usage Date",
    ROUND(SUM(db_storage_tb) OVER ( ORDER BY dsu.usage_date ROWS BETWEEN 30 PRECEDING AND CURRENT ROW),2) AS "DB Storage TB",
    --ROUND(db_storage_tb,1) AS "DB Storage TBs",
    ROUND(SUM(failsafe_storage_tb) OVER ( ORDER BY dsu.usage_date ROWS BETWEEN 30 PRECEDING AND CURRENT ROW),2) AS "Failsafe Storage TB", --ROUND(failsafe_storage_tb,1) AS "Failsafe Storage TBs",
    ROUND(SUM(stage_tb) OVER ( ORDER BY dsu.usage_date ROWS BETWEEN 30 PRECEDING AND CURRENT ROW),2) AS "Stage Storage TB",
    "DB Storage TB" + "Failsafe Storage TB" + "Stage Storage TB" AS "Storage TB"
    FROM db_storage_usage dsu
    LEFT JOIN stage_usage ssu ON ssu.usage_date = dsu.usage_date
    ORDER BY 1 DESC
    LIMIT 365;
    """
    credits_by_month_sql = """
    SELECT DATE_TRUNC('month', convert_timezone('UTC',usage_date))::DATE usage_month,
    service_type,
    ROUND(SUM(credits_used_COMPUTE)) AS credits_used
    FROM HUB_DB.HUB_CONS_SC.METERING_DAILY_HISTORY_ALL mdh
    WHERE usage_date BETWEEN convert_timezone('UTC',date_trunc('month', dateadd('month',-12,current_timestamp()))) AND current_timestamp()
    GROUP BY ALL;
    """

    credits_bm_table_sql = """
    WITH main_query AS
    (
    SELECT DATE_TRUNC('month', convert_timezone('UTC',usage_date))::DATE usage_month,
    service_type,
    ROUND(SUM(credits_used_COMPUTE)) AS credits_used
    FROM HUB_DB.HUB_CONS_SC.METERING_DAILY_HISTORY_ALL mdh
    WHERE usage_date BETWEEN convert_timezone('UTC',date_trunc('month', dateadd('month',-12,current_timestamp()))) AND current_timestamp()
    GROUP BY ALL
    )
    SELECT * FROM main_query
    PIVOT(SUM(credits_used) FOR usage_month IN (ANY)
    DEFAULT ON NULL(0))
    ORDER BY service_type;
    """

    st.title("Organization Billable Credits")
    
    # Execute both queries
    compute_l30 = session.sql(compute_l30_sql).collect()
    storage_l30 = session.sql(storage_l30_sql).collect()



    # if compute_l30 and storage_l30 and compute_by_day:
    compute_l30_df = pd.DataFrame(compute_l30)
    storage_l30_df = pd.DataFrame(storage_l30)

   
    # Create figure with indicator subplot type
    fig = make_subplots(
        rows=2, cols=3,
        specs=[
            [{'type': 'indicator'}, {'type': 'indicator'}, {'type': 'indicator'}],
            [{'type': 'indicator'}, {'type': 'indicator'}, {'type': 'indicator'}]
        ]
        # ,
        # subplot_titles=("Compute Credits", "Storage Usage")
    )
    
    # Add traces for compute metrics
    fig.add_trace(
        go.Indicator(
            mode="number+delta",
            value=compute_l30_df['CREDITS_USED_LAST_PERIOD'].iloc[0],
            title={"text": "Compute Credits Used<br>Last 30 Days"},
            delta={'reference': compute_l30_df['CREDITS_USED_PRIOR_PERIOD'].iloc[0]},
        ),
        row=1, col=1
    )
    
    fig.add_trace(
        go.Indicator(
            mode="number+delta",
            value=compute_l30_df['PCT_CHANGE'].iloc[0],
            title={"text": "Compute Credits<br>% Change"},
            number={'suffix': "%"},
        ),
        row=1, col=3
    )
    
    # Add traces for storage metrics
    fig.add_trace(
        go.Indicator(
            mode="number+delta",
            value=storage_l30_df['Avg Storage Last 30 Days (TB)'].iloc[0],
            title={"text": "Total Storage<br>Last 30 Days (TB)"},
            delta={'reference': storage_l30_df['Avg Storage Prior 30 Days\n    (TB)'].iloc[0]},
        ),
        row=2, col=1
    )
    
    fig.add_trace(
        go.Indicator(
            mode="number+delta",
            value=storage_l30_df['Avg DB Storage Last 30 Days (TB)'].iloc[0],
            title={"text": "DB Storage<br>Last 30 Days (TB)"},
            delta={'reference': storage_l30_df['Avg DB Storage Prior 30 Days (TB)'].iloc[0]},
        ),
        row=2, col=2
    )
    
    fig.add_trace(
        go.Indicator(
            mode="number+delta",
            value=storage_l30_df['Avg Stage Storage Last 30 Days (TB)'].iloc[0],
            title={"text": "Stage Storage<br>Last 30 Days (TB)"},
            delta={'reference': storage_l30_df['Avg Stage Storage Prior 30 Days (TB)'].iloc[0]},
        ),
        row=2, col=3
    )
    
    # Update layout
    fig.update_layout(
        height=600,
        grid={'rows': 2, 'columns': 3, 'pattern': "independent"},
        showlegend=False
    )
    
    # Display the chart using Streamlit
    st.plotly_chart(fig, use_container_width=True)

    compute_by_day = session.sql(compute_by_day_sql).collect()
    compute_by_day_df = pd.DataFrame(compute_by_day)

    # Create vertical bar chart for compute by day
    compute_fig = go.Figure(go.Bar(
        x=compute_by_day_df['USAGE_WEEK'],
        y=compute_by_day_df['Compute Credits Used'],
    ))
    
    compute_fig.update_layout(
        title="Daily Compute Credits Usage",
        xaxis_title="Date",
        yaxis_title="Compute Credits Used",
        height=400,
        xaxis={'type': 'date'}  # Ensure proper date formatting
    )
    
    st.plotly_chart(compute_fig, use_container_width=True)

    storage_by_day = session.sql(storage_by_day_sql).collect()
    storage_by_day_df = pd.DataFrame(storage_by_day)
    
   

    # Create storage usage bar chart
    storage_fig = go.Figure()
    
    # Add traces for each storage type
    storage_fig.add_trace(go.Bar(
        x=storage_by_day_df['Usage Date'],
        y=storage_by_day_df['DB Storage TB'],
        name='DB Storage'
    ))
    
    storage_fig.add_trace(go.Bar(
        x=storage_by_day_df['Usage Date'],
        y=storage_by_day_df['Failsafe Storage TB'],
        name='Failsafe Storage'
    ))
    
    storage_fig.add_trace(go.Bar(
        x=storage_by_day_df['Usage Date'],
        y=storage_by_day_df['Stage Storage TB'],
        name='Stage Storage'
    ))
    
    # Update layout
    storage_fig.update_layout(
        title="Daily Storage Usage by Type",
        xaxis_title="Date",
        yaxis_title="Storage (TB)",
        barmode='stack',
        height=400
    )
    
    st.plotly_chart(storage_fig, use_container_width=True)

    credits_by_month = session.sql(credits_by_month_sql).collect()
    credits_by_month_df = pd.DataFrame(credits_by_month)
    # Create bar chart for monthly credits by service type
    credits_fig = go.Figure()
    
    # Add trace for each service type
    for service in credits_by_month_df['SERVICE_TYPE'].unique():
        service_data = credits_by_month_df[credits_by_month_df['SERVICE_TYPE'] == service]
        credits_fig.add_trace(go.Bar(
            x=service_data['USAGE_MONTH'],
            y=service_data['CREDITS_USED'],
            name=service
        ))
    
    # Update layout
    credits_fig.update_layout(
        title="Monthly Credits Usage by Service Type",
        xaxis_title="Month",
        yaxis_title="Credits Used",
        barmode='stack',
        height=400,
        xaxis={'type': 'date'}
    )
    
    st.plotly_chart(credits_fig, use_container_width=True)

    # Execute credits by month table query and create dataframe
    credits_bm_table = session.sql(credits_bm_table_sql).collect()
    credits_bm_table_df = pd.DataFrame(credits_bm_table)
    
    # Create a styled table using Streamlit
    st.subheader("Monthly Credits Usage by Service Type")
    st.dataframe(
        credits_bm_table_df.style.format({
            col: "{:,.0f}" for col in credits_bm_table_df.columns if col != 'SERVICE_TYPE'
        }),
        use_container_width=True
    )
