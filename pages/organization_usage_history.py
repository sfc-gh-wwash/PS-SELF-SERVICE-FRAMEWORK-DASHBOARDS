# Generated by Snowflake Copilot
# Import python packages
import streamlit as st
import plotly
from snowflake.snowpark.context import get_active_session
# Import required packages
import plotly.graph_objects as go
import pandas as pd

# import app pages
# from sql.org_billable_credits import org_billable_usage

from plotly.subplots import make_subplots
session = get_active_session()

def org_usage_history():
    # Generated by Snowflake Copilot
    # Get account names
    acct_name_sql = """
    SELECT DISTINCT account_name 
    FROM snowflake.organization_usage.warehouse_metering_history
    ORDER BY account_name;
    """
    
    # Get account names into a list
    acct_df = session.sql(acct_name_sql).to_pandas()
    acct_list = acct_df['ACCOUNT_NAME'].tolist()
    acct_list.insert(0, 'ALL') # Add ALL option at beginning
    
    # Add multi-select dropdown
    selected_accts = st.multiselect(
        'Select Accounts',
        options=acct_list,
        default=['ALL']
    )
    
    # Handle ALL selection logic
    if 'ALL' in selected_accts:
        selected_acct_str = "'ALL'"
    else:
        selected_acct_str = "'" + "','".join(selected_accts) + "'"
    
    # Modify SQL queries to use selected accounts
    # Example modification for compute_credits_by_wh_mo_sql:


    compute_credits_l30_sql = f"""
    WITH usage_detail_rows AS
    (
    SELECT
    convert_timezone('America/Chicago',current_timestamp()) AS local_cts,
    convert_timezone('America/Chicago',start_time) AS local_start_time,
    CASE WHEN local_start_time BETWEEN date_trunc('day', dateadd('day',-29,local_cts)) AND local_cts
    THEN credits_used_compute ELSE 0 END AS credits_used_last_period,
    CASE WHEN local_start_time BETWEEN date_trunc('day', dateadd('day',-29,local_cts)) AND local_cts
    THEN 0 ELSE credits_used_compute END AS credits_used_prior_period
    FROM snowflake.organization_usage.warehouse_metering_history
    WHERE local_start_time BETWEEN date_trunc('day', dateadd('day',-59,local_cts)) AND local_cts AND
    (account_name IN ({selected_acct_str}) or 'ALL' = {selected_acct_str})
    )
    SELECT
    ROUND(SUM(credits_used_last_period),0) AS credits_used_last_period,
    ROUND(SUM(credits_used_prior_period),0) AS credits_used_prior_period,
    100*(SUM(credits_used_last_period) - nullif(SUM(credits_used_prior_period),0)) /
    (SUM(credits_used_prior_period) ) AS pct_change
    FROM usage_detail_rows
    ;"""

    
    pipe_credits_l30_sql = f"""
    WITH usage_detail_rows AS
    (
    SELECT
    convert_timezone('America/Chicago',current_timestamp()) AS local_cts,
    convert_timezone('America/Chicago',start_time) AS local_start_time,
    CASE WHEN local_start_time BETWEEN date_trunc('day', dateadd('day',-29,local_cts)) AND local_cts
    THEN credits_used_compute ELSE 0 END AS credits_used_last_period,
    CASE WHEN local_start_time BETWEEN date_trunc('day', dateadd('day',-29,local_cts)) AND local_cts
    THEN 0 ELSE credits_used_compute END AS credits_used_prior_period
    FROM snowflake.organization_usage.warehouse_metering_history
    WHERE local_start_time BETWEEN date_trunc('day', dateadd('day',-59,local_cts)) AND local_cts AND
    (account_name IN ({selected_acct_str}) or 'ALL' = {selected_acct_str})
    )
    SELECT
    ROUND(SUM(credits_used_last_period),0) AS credits_used_last_period,
    ROUND(SUM(credits_used_prior_period),0) AS credits_used_prior_period,
    100*(SUM(credits_used_last_period) - nullif(SUM(credits_used_prior_period),0)) /
    (SUM(credits_used_prior_period) ) AS pct_change
    FROM usage_detail_rows
    ;"""

    db_avg_storage_l30_sql = f"""
    WITH usage_detail_rows AS
    (
    SELECT
    convert_timezone('America/Chicago',current_timestamp()) AS local_cts,
    convert_timezone('America/Chicago',usage_date) AS local_usage_date,
    account_name, region, organization_name,
    average_database_bytes,
    CASE WHEN local_usage_date BETWEEN date_trunc('day', dateadd('day',-29,local_cts)) AND
    local_cts THEN average_database_bytes ELSE 0 END AS storage_last_period,
    CASE WHEN local_usage_date BETWEEN date_trunc('day', dateadd('day',-29,local_cts)) AND
    local_cts THEN 0 ELSE average_database_bytes END AS storage_prior_period
     FROM snowflake.organization_usage.database_storage_usage_history
    WHERE local_usage_date BETWEEN date_trunc('day', dateadd('day',-59,local_cts)) AND
    local_cts AND (account_name IN ({selected_acct_str}) or 'ALL' = {selected_acct_str})
    ),
    storage_by_account_and_day AS
    (
    SELECT
    local_usage_date,
    SUM(storage_last_period) AS total_storage_last_period,
    SUM(storage_prior_period) AS total_storage_prior_period
    FROM
    usage_detail_rows
    GROUP BY local_usage_date
    )
    SELECT
     ROUND((SUM(total_storage_last_period) / 30) / POWER(2,40) ,2) AS storage_last_period,
     ROUND((SUM(total_storage_prior_period) / 30) / POWER(2,40) ,2) AS storage_prior_period
    FROM storage_by_account_and_day
    ;"""

    compute_credits_l7_sql = f"""
    WITH usage_detail_rows AS
    (
    SELECT
    convert_timezone('America/Chicago',current_timestamp()) AS local_cts,
    convert_timezone('America/Chicago',start_time) AS local_start_time,
    CASE WHEN local_start_time BETWEEN date_trunc('day', dateadd('day',-6,local_cts)) AND
    current_timestamp() THEN credits_used_compute ELSE 0 END AS credits_used_last_period,
    CASE WHEN local_start_time BETWEEN date_trunc('day', dateadd('day',-6,local_cts)) AND
    current_timestamp() THEN 0 ELSE credits_used_compute END AS credits_used_prior_period
    FROM snowflake.organization_usage.warehouse_metering_history
    WHERE local_start_time BETWEEN date_trunc('day', dateadd('day',-13,local_cts)) AND local_cts AND
    (account_name IN ({selected_acct_str}) or 'ALL' = {selected_acct_str})
    )
    SELECT
    ROUND(SUM(credits_used_last_period),0) AS credits_used_last_period,
    ROUND(SUM(credits_used_prior_period),0) AS credits_used_prior_period,
    100*(SUM(credits_used_last_period) - nullif(SUM(credits_used_prior_period),0)) /
    (SUM(credits_used_prior_period) ) AS pct_change
    FROM usage_detail_rows
    ;"""

    pipe_credits_l7_sql = f"""
    WITH usage_detail_rows AS
    (
    SELECT
    convert_timezone('America/Chicago',current_timestamp()) AS local_cts,
    convert_timezone('America/Chicago',usage_date) AS local_usage_date,
    CASE WHEN local_usage_date BETWEEN date_trunc('day', dateadd('day',-6,local_cts)) AND
    current_timestamp() THEN credits_used ELSE 0 END AS credits_used_last_period,
    CASE WHEN local_usage_date BETWEEN date_trunc('day', dateadd('day',-6,local_cts)) AND
    current_timestamp() THEN 0 ELSE credits_used END AS credits_used_prior_period
    FROM snowflake.organization_usage.pipe_usage_history
    WHERE local_usage_date BETWEEN date_trunc('day', dateadd('day',-13,local_cts)) AND local_cts AND
    (account_name IN ({selected_acct_str}) or 'ALL' = {selected_acct_str})
    )
    SELECT
    ROUND(SUM(credits_used_last_period),0) AS credits_used_last_period,
    ROUND(SUM(credits_used_prior_period),0) AS credits_used_prior_period,
    100*(SUM(credits_used_last_period) - nullif(SUM(credits_used_prior_period),0)) /
    (SUM(credits_used_prior_period) ) AS pct_change
    FROM usage_detail_rows
    ;"""

    db_avg_storage_l7_sql = f"""
    WITH usage_detail_rows AS
    (
    SELECT
    convert_timezone('America/Chicago',current_timestamp()) AS local_cts,
    convert_timezone('America/Chicago',usage_date) AS local_usage_date,
    account_name, region, organization_name,
    average_database_bytes,
    CASE WHEN local_usage_date BETWEEN date_trunc('day', dateadd('day',-6,local_cts)) AND local_cts
    THEN average_database_bytes ELSE 0 END AS storage_last_period,
    CASE WHEN local_usage_date BETWEEN date_trunc('day', dateadd('day',-6,local_cts)) AND local_cts
    THEN 0 ELSE average_database_bytes END AS storage_prior_period
    FROM snowflake.organization_usage.database_storage_usage_history
    WHERE local_usage_date BETWEEN date_trunc('day', dateadd('day',-13,local_cts)) AND local_cts AND
    (account_name IN ({selected_acct_str}) or 'ALL' = {selected_acct_str})
    ),
    storage_by_account_and_day AS
    (
    SELECT
    local_usage_date,
    SUM(storage_last_period) AS total_storage_last_period,
    SUM(storage_prior_period) AS total_storage_prior_period
    FROM
    usage_detail_rows
    GROUP BY local_usage_date
    )
    SELECT
    ROUND((SUM(total_storage_last_period) / 7) / POWER(2,40) ,2) AS storage_last_period,
    ROUND((SUM(total_storage_prior_period) / 7) / POWER(2,40) ,2) AS storage_prior_period
    FROM storage_by_account_and_day
    ;"""

    compute_credits_l1_sql = f"""
      WITH usage_detail_rows AS
    (
    SELECT
    convert_timezone('America/Chicago',current_timestamp()) AS local_cts,
    convert_timezone('America/Chicago',start_time) AS local_start_time,
    CASE WHEN local_start_time BETWEEN date_trunc('day', dateadd('day',-1,local_cts)) AND
    current_timestamp() THEN credits_used_compute ELSE 0 END AS credits_used_last_period,
    CASE WHEN local_start_time BETWEEN date_trunc('day', dateadd('day',-2,local_cts)) AND
    current_timestamp() THEN 0 ELSE credits_used_compute END AS credits_used_prior_period
    FROM snowflake.organization_usage.warehouse_metering_history
    WHERE local_start_time BETWEEN date_trunc('day', dateadd('day',-2,local_cts)) AND local_cts AND
    (account_name IN ({selected_acct_str}) or 'ALL' = {selected_acct_str})
    )
    SELECT
    ROUND(SUM(credits_used_last_period),0) AS credits_used_last_period,
    ROUND(SUM(credits_used_prior_period),0) AS credits_used_prior_period,
    100*(SUM(credits_used_last_period) - nullif(SUM(credits_used_prior_period),0)) /
    (SUM(credits_used_prior_period) ) AS pct_change
    FROM usage_detail_rows
    ;"""

    pipe_credits_l1_sql = f"""
    WITH usage_detail_rows AS
    (
    SELECT
    convert_timezone('America/Los_Angeles',current_timestamp()) AS local_cts,
    convert_timezone('America/Los_Angeles',start_time) AS local_start_time,
    CASE WHEN local_start_time >= date_trunc('day', dateadd('day',-1,local_cts)) AND local_start_time <
    date_trunc('day', dateadd('day',0,local_cts))THEN credits_used_compute ELSE 0 END AS
    credits_used_last_period,
    CASE WHEN local_start_time >= date_trunc('day', dateadd('day',-1,local_cts)) AND local_start_time <
    date_trunc('day', dateadd('day',0,local_cts)) THEN 0 ELSE credits_used_compute END AS
    credits_used_prior_period
    FROM snowflake.organization_usage.warehouse_metering_history
    WHERE local_start_time >= date_trunc('day', dateadd('day',-2,local_cts)) AND local_start_time <
    date_trunc('day', dateadd('day',0,local_cts)) AND (account_name IN ({selected_acct_str}) or 'ALL' = {selected_acct_str})
    )
    SELECT
    ROUND(SUM(credits_used_last_period),0) AS credits_used_last_period,
    ROUND(SUM(credits_used_prior_period),0) AS credits_used_prior_period,
    100*(SUM(credits_used_last_period) - nullif(SUM(credits_used_prior_period),0)) /
    (SUM(credits_used_prior_period) ) AS pct_change
    FROM usage_detail_rows
    ;"""

    db_avg_storage_l1_sql = f"""
    WITH usage_detail_rows AS
    (
    SELECT
    convert_timezone('America/Chicago',current_timestamp()) AS local_cts,
    convert_timezone('America/Chicago',usage_date) AS local_usage_date,
    account_name, region, organization_name,
    average_database_bytes,
    CASE WHEN local_usage_date >= date_trunc('day', dateadd('day',-1,local_cts)) AND local_usage_date <
    date_trunc('day', dateadd('day',0,local_cts))THEN average_database_bytes ELSE 0 END AS
    storage_last_period,
    CASE WHEN local_usage_date >= date_trunc('day', dateadd('day',-1,local_cts)) AND local_usage_date <
    date_trunc('day', dateadd('day',0,local_cts)) THEN 0 ELSE average_database_bytes END AS
    storage_prior_period
    FROM snowflake.organization_usage.database_storage_usage_history
    WHERE local_usage_date >= date_trunc('day', dateadd('day',-2,local_cts)) AND local_usage_date <
    date_trunc('day', dateadd('day',0,local_cts)) AND (account_name IN ({selected_acct_str}) or 'ALL' = {selected_acct_str})
    ),
    storage_by_account_and_day AS
    (
    SELECT
    local_usage_date,
    SUM(storage_last_period) AS total_storage_last_period,
    SUM(storage_prior_period) AS total_storage_prior_period
    FROM
    usage_detail_rows
    GROUP BY local_usage_date
    )
    SELECT
    ROUND((SUM(total_storage_last_period) / 1) / POWER(2,40) ,2) AS storage_last_period,
    ROUND((SUM(total_storage_prior_period) / 1) / POWER(2,40) ,2) AS storage_prior_period
    FROM storage_by_account_and_day
    ;"""

    compute_credits_by_acct_mo_sql = f"""
    WITH query_details AS
    (
    SELECT
    convert_timezone('America/Chicago',current_timestamp()) AS local_cts,
    convert_timezone('America/Chicago',start_time) AS local_start_time,
    DATE_TRUNC('month', local_start_time)::DATE usage_month
    ,account_name
    ,credits_used_compute
    ,credits_used_cloud_services
    FROM snowflake.organization_usage.warehouse_metering_history
    WHERE local_start_time BETWEEN date_trunc('month', dateadd('month',-5,local_cts)) AND local_cts
    AND (account_name IN ({selected_acct_str}) or 'ALL' = {selected_acct_str})
    )
    SELECT usage_month, account_name
    ,ROUND(SUM(credits_used_compute),0) AS "Compute Credits"
    ,ROUND(SUM(credits_used_cloud_services),0) "Credits Used Cloud Svcs"
    ,CASE WHEN "Credits Used Cloud Svcs" - (SUM(credits_used_compute) / 10) > 0
    THEN "Credits Used Cloud Svcs" - ROUND((SUM(credits_used_compute) / 10)) ELSE 0 END AS "Cloud
    Services Credits Adj"
    FROM query_details
    GROUP BY 1,2
    ORDER BY 1,2;"""
    
    compute_credits_by_acct_wk_sql = f"""
    WITH query_details AS
    (
    SELECT
    convert_timezone('America/Chicago',current_timestamp()) AS local_cts,
    convert_timezone('America/Chicago',start_time) AS local_start_time,
    DATE_TRUNC('week', local_start_time)::DATE usage_week
    ,account_name
    ,credits_used_compute
    ,credits_used_cloud_services
    FROM snowflake.organization_usage.warehouse_metering_history
    WHERE local_start_time BETWEEN date_trunc('week', dateadd('week',-10,local_cts)) AND local_cts
    AND (account_name IN ({selected_acct_str}) or 'ALL' = {selected_acct_str})
    )
    SELECT usage_week, account_name
    ,ROUND(SUM(credits_used_compute),0) AS "Compute Credits"
    ,ROUND(SUM(credits_used_cloud_services),0) "Credits Used Cloud Svcs"
    ,CASE WHEN "Credits Used Cloud Svcs" - (SUM(credits_used_compute) / 10) > 0
    THEN "Credits Used Cloud Svcs" - ROUND((SUM(credits_used_compute) / 10)) ELSE 0 END AS "Cloud
    Services Credits Adj"
    FROM query_details
    GROUP BY 1,2
    ORDER BY 1,2;
    """
    compute_credits_by_acct_dy_sql = f"""
    WITH query_details AS
    (
    SELECT
    convert_timezone('America/Chicago',current_timestamp()) AS local_cts,
    convert_timezone('America/Chicago',start_time) AS local_start_time,
    DATE_TRUNC('week', local_start_time)::DATE usage_week
    ,account_name
    ,credits_used_compute
    ,credits_used_cloud_services
    FROM snowflake.organization_usage.warehouse_metering_history
    WHERE local_start_time BETWEEN date_trunc('week', dateadd('week',-10,local_cts)) AND local_cts
    AND  (account_name IN ({selected_acct_str}) or 'ALL' = {selected_acct_str})
    )
    SELECT usage_week, account_name
    ,ROUND(SUM(credits_used_compute),0) AS "Compute Credits"
    ,ROUND(SUM(credits_used_cloud_services),0) "Credits Used Cloud Svcs"
    ,CASE WHEN "Credits Used Cloud Svcs" - (SUM(credits_used_compute) / 10) > 0
    THEN "Credits Used Cloud Svcs" - ROUND((SUM(credits_used_compute) / 10)) ELSE 0 END AS "Cloud
    Services Credits Adj"
    FROM query_details
    GROUP BY 1,2
    ORDER BY 1,2;
    """

    pipe_credits_by_acct_mo_sql = f"""
    WITH query_details AS
    (
    SELECT
    convert_timezone('America/Chicago',current_date()) AS local_cdate,
    convert_timezone('America/Chicago',usage_date) AS local_usage_date,
    account_name,
    pipe_name
    usage_date,
    DATE_TRUNC('month', usage_date)::DATE usage_month,
    credits_used,
    bytes_inserted,
    files_inserted
    FROM snowflake.organization_usage.pipe_usage_history
    WHERE local_usage_date BETWEEN date_trunc('month', dateadd('month',-6,local_cdate)) AND
    local_cdate AND (account_name IN ({selected_acct_str}) or 'ALL' = {selected_acct_str})
    )
    SELECT
    usage_month, account_name,
    ROUND(SUM(credits_used),0) AS "Credits Used",
    ROUND(SUM(bytes_inserted ),0) AS "Bytes Inserted",
    ROUND(SUM(files_inserted ),0) AS "Files Inserted"
    FROM query_details
    GROUP BY ALL
    ORDER BY 1,2
    ;
    """

    pipe_credits_by_acct_wk_sql = f"""
    WITH query_details AS
    (
    SELECT
    convert_timezone('America/Chicago',current_date()) AS local_cdate,
    convert_timezone('America/Chicago',usage_date) AS local_usage_date,
    account_name,
    pipe_name
    usage_date,
    DATE_TRUNC('week', usage_date)::DATE usage_week,
    credits_used,
    bytes_inserted,
    files_inserted
    FROM snowflake.organization_usage.pipe_usage_history
    WHERE local_usage_date BETWEEN date_trunc('week', dateadd('week',-10,local_cdate)) AND
    local_cdate AND (account_name IN ({selected_acct_str}) or 'ALL' = {selected_acct_str})
    )
    SELECT
    usage_week, account_name,
    ROUND(SUM(credits_used),0) AS "Credits Used",
    ROUND(SUM(bytes_inserted ),0) AS "Bytes Inserted",
    ROUND(SUM(files_inserted ),0) AS "Files Inserted"
    FROM query_details
    GROUP BY ALL
    ORDER BY 1,2
    ;
    """

    pipe_credits_by_acct_dy_sql = f"""
    WITH query_details AS
    (
    SELECT
    convert_timezone('America/Chicago',current_date()) AS local_cdate,
    convert_timezone('America/Chicago',usage_date) AS local_usage_date,
    account_name,
    pipe_name
    usage_date,
    DATE_TRUNC('day', usage_date)::DATE usage_day,
    credits_used,
    bytes_inserted,
    files_inserted
    FROM snowflake.organization_usage.pipe_usage_history
    WHERE local_usage_date BETWEEN date_trunc('day', dateadd('day',-56,local_cdate)) AND local_cdate
    AND (account_name IN ({selected_acct_str}) or 'ALL' = {selected_acct_str})
    )
    SELECT
    usage_day, account_name,
    ROUND(SUM(credits_used),0) AS "Credits Used",
    ROUND(SUM(bytes_inserted ),0) AS "Bytes Inserted",
    ROUND(SUM(files_inserted ),0) AS "Files Inserted"
    FROM query_details
    GROUP BY ALL
    ORDER BY 1,2
    ;
    """

    db_storage_by_acct_mo_sql = f"""
    WITH query_details AS
    (
    -- This sums up for all databases within the usage date and account
    SELECT
    convert_timezone('America/Chicago',current_date()) AS local_cdate,
    convert_timezone('America/Chicago',usage_date) AS local_usage_date,
    account_name,
    usage_date,
    SUM(average_database_bytes ) AS total_db_bytes_per_day,
    SUM(average_failsafe_bytes ) AS total_fs_bytes_per_day
    FROM snowflake.organization_usage.database_storage_usage_history
    WHERE local_usage_date BETWEEN date_trunc('month', dateadd('month',-6,local_cdate)) AND
    local_cdate AND (account_name IN ({selected_acct_str}) or 'ALL' = {selected_acct_str})
    GROUP BY usage_date, account_name
    )
    -- Get the Average Daily per month and account
    SELECT
    DATE_TRUNC('month', usage_date)::DATE usage_month,
    account_name,
    ROUND(AVG(total_db_bytes_per_day) / POWER(2, 40),2) AS "Avg DB TB",
    ROUND(AVG(total_fs_bytes_per_day) / POWER(2, 40),4) AS "Avg Failsafe TB"
    FROM query_details
    GROUP BY ALL
    ORDER BY 1,2
    ;
    """

    db_storage_by_acct_wk_sql = f"""
    WITH query_details AS
    (
    -- This sums up for all databases within the usage date and account
    SELECT
    convert_timezone('America/Chicago',current_date()) AS local_cdate,
    convert_timezone('America/Chicago',usage_date) AS local_usage_date,
    account_name,
    usage_date,
    SUM(average_database_bytes ) AS total_db_bytes_per_day,
    SUM(average_failsafe_bytes ) AS total_fs_bytes_per_day
    FROM snowflake.organization_usage.database_storage_usage_history
    WHERE local_usage_date BETWEEN date_trunc('week', dateadd('week',-10,local_cdate)) AND
    local_cdate AND (account_name IN ({selected_acct_str}) or 'ALL' = {selected_acct_str})
    GROUP BY usage_date, account_name
    )
    -- Get the Average Daily per month and account
    SELECT
    DATE_TRUNC('week', usage_date)::DATE usage_week,
    account_name,
    ROUND(AVG(total_db_bytes_per_day) / POWER(2, 40),2) AS "Avg DB TB",
    ROUND(AVG(total_fs_bytes_per_day) / POWER(2, 40),4) AS "Avg Failsafe TB"
    FROM query_details
    GROUP BY ALL
    ORDER BY 1,2
    ;
    """

    db_storage_by_acct_dy_sql = f"""
    WITH query_details AS
    (
    -- This sums up for all databases within the usage date and account
    SELECT
    convert_timezone('America/Chicago',current_date()) AS local_cdate,
    convert_timezone('America/Chicago',usage_date) AS local_usage_date,
    account_name,
    usage_date,
    SUM(average_database_bytes ) AS total_db_bytes_per_day,
    SUM(average_failsafe_bytes ) AS total_fs_bytes_per_day
    FROM snowflake.organization_usage.database_storage_usage_history
    WHERE local_usage_date BETWEEN date_trunc('week', dateadd('week',-10,local_cdate)) AND
    local_cdate AND (account_name IN ({selected_acct_str}) or 'ALL' = {selected_acct_str})
    GROUP BY usage_date, account_name
    )
    -- Get the Average Daily per month and account
    SELECT
    DATE_TRUNC('day', usage_date)::DATE usage_day,
    account_name,
    ROUND(AVG(total_db_bytes_per_day) / POWER(2, 40),2) AS "Avg DB TB",
    ROUND(AVG(total_fs_bytes_per_day) / POWER(2, 40),4) AS "Avg Failsafe TB"
    FROM query_details
    GROUP BY ALL
    ORDER BY 1,2
    ;
    """

    
    # Generated by Snowflake Copilot
    # Execute the query
    compute_credits_l30_df = session.sql(compute_credits_l30_sql).to_pandas()
    pipe_credits_l30_df = session.sql(pipe_credits_l30_sql).to_pandas()
    db_avg_storage_l30_df = session.sql(db_avg_storage_l30_sql).to_pandas()
    compute_credits_l7_df = session.sql(compute_credits_l7_sql).to_pandas()
    pipe_credits_l7_df = session.sql(pipe_credits_l7_sql).to_pandas()
    db_avg_storage_l7_df = session.sql(db_avg_storage_l7_sql).to_pandas()
    compute_credits_l1_df = session.sql(compute_credits_l1_sql).to_pandas()
    pipe_credits_l1_df = session.sql(pipe_credits_l1_sql).to_pandas()
    db_avg_storage_l1_df = session.sql(db_avg_storage_l1_sql).to_pandas()


    
        # Create figure with indicator subplot type
    credits_fig = make_subplots(
        rows=3, cols=3,
        specs=[
            [{'type': 'indicator'}, {'type': 'indicator'}, {'type': 'indicator'}],
            [{'type': 'indicator'}, {'type': 'indicator'}, {'type': 'indicator'}],
            [{'type': 'indicator'}, {'type': 'indicator'}, {'type': 'indicator'}]
        ]
        # ,
        # subplot_titles=("Compute Credits", "Storage Usage")
    )
    
    # Add traces for compute metrics
    credits_fig.add_trace(
        go.Indicator(
            mode="number+delta",
            value=compute_credits_l30_df['CREDITS_USED_LAST_PERIOD'].iloc[0],
            title={"text": "Compute Credits Used<br>Last 30 Days"},
            delta={'reference': compute_credits_l30_df['CREDITS_USED_PRIOR_PERIOD'].iloc[0]},
        ),
        row=1, col=1
    )

    credits_fig.add_trace(
        go.Indicator(
            mode="number+delta",
            value=compute_credits_l7_df['CREDITS_USED_LAST_PERIOD'].iloc[0],
            title={"text": "Compute Credits Used<br>Last 7 Days"},
            delta={'reference': compute_credits_l7_df['CREDITS_USED_PRIOR_PERIOD'].iloc[0]},
        ),
        row=2, col=1
    )
    
    credits_fig.add_trace(
        go.Indicator(
            mode="number+delta",
            value=compute_credits_l1_df['CREDITS_USED_LAST_PERIOD'].iloc[0],
            title={"text": "Compute Credits Used<br>Last 1 Day"},
            delta={'reference': compute_credits_l1_df['CREDITS_USED_PRIOR_PERIOD'].iloc[0]},
        ),
        row=3, col=1
    )

    # Add traces for pipe metrics
    credits_fig.add_trace(
        go.Indicator(
            mode="number+delta",
            value=pipe_credits_l30_df['CREDITS_USED_LAST_PERIOD'].iloc[0],
            title={"text": "Pipe Credits Used<br>Last 30 Days"},
            delta={'reference': pipe_credits_l30_df['CREDITS_USED_PRIOR_PERIOD'].iloc[0]},
        ),
        row=1, col=2
    )

    credits_fig.add_trace(
        go.Indicator(
            mode="number+delta",
            value=pipe_credits_l7_df['CREDITS_USED_LAST_PERIOD'].iloc[0],
            title={"text": "Pipe Credits Used<br>Last 7 Days"},
            delta={'reference': pipe_credits_l7_df['CREDITS_USED_PRIOR_PERIOD'].iloc[0]},
        ),
        row=2, col=2
    )

    credits_fig.add_trace(
        go.Indicator(
            mode="number+delta",
            value=pipe_credits_l1_df['CREDITS_USED_LAST_PERIOD'].iloc[0],
            title={"text": "Pipe Credits Used<br>Last 1 Day"},
            delta={'reference': pipe_credits_l1_df['CREDITS_USED_PRIOR_PERIOD'].iloc[0]},
        ),
        row=3, col=2
    )

    # Add traces for storage metrics
    credits_fig.add_trace(
        go.Indicator(
            mode="number+delta",
            value=db_avg_storage_l30_df['STORAGE_LAST_PERIOD'].iloc[0],
            title={"text": "Storage Used<br>Last 30 Days"},
            delta={'reference': db_avg_storage_l30_df['STORAGE_PRIOR_PERIOD'].iloc[0]},
        ),
        row=1, col=3
    )

    credits_fig.add_trace(
        go.Indicator(
            mode="number+delta",
            value=db_avg_storage_l7_df['STORAGE_LAST_PERIOD'].iloc[0],
            title={"text": "Storage Used<br>Last 7 Days"},
            delta={'reference': db_avg_storage_l7_df['STORAGE_PRIOR_PERIOD'].iloc[0]},
        ),
        row=2, col=3
    )

    credits_fig.add_trace(
        go.Indicator(
            mode="number+delta",
            value=db_avg_storage_l1_df['STORAGE_LAST_PERIOD'].iloc[0],
            title={"text": "Storage Used<br>Last 1 Day"},
            delta={'reference': db_avg_storage_l1_df['STORAGE_PRIOR_PERIOD'].iloc[0]},
        ),
        row=3, col=3
    )

        # Update layout
    credits_fig.update_layout(
        height=600,
        grid={'rows': 3, 'columns': 3, 'pattern': "independent"},
        showlegend=False
    )
    
    # Display the chart using Streamlit
    st.plotly_chart(credits_fig, use_container_width=True)


    # Generated by Snowflake Copilot
    # Execute the query
    compute_credits_acct_mo_df = session.sql(compute_credits_by_acct_mo_sql).to_pandas()
    
    # Create bar chart
    compute_credits_acct_mo_fig = go.Figure()
    
    # Add bars for each account
    for account in compute_credits_acct_mo_df['ACCOUNT_NAME'].unique():
        account_data = compute_credits_acct_mo_df[compute_credits_acct_mo_df['ACCOUNT_NAME'] == account]
        compute_credits_acct_mo_fig.add_trace(go.Bar(
            x=account_data['USAGE_MONTH'],
            y=account_data['Compute Credits'],
            name=account
        ))
    
    # Update layout
    compute_credits_acct_mo_fig.update_layout(
        title='Monthly Compute Credits by Account',
        xaxis_title='Usage Month',
        yaxis_title='Compute Credits',
        barmode='group',
        height=500,
        showlegend=True
    )
    
    # Display the chart
    st.plotly_chart(compute_credits_acct_mo_fig, use_container_width=True)


    # Generated by Snowflake Copilot
    # Execute the query
    compute_credits_acct_wk_df = session.sql(compute_credits_by_acct_wk_sql).to_pandas()
    
    # Create bar chart
    compute_credits_acct_wk_fig = go.Figure()
    
    # Add bars for each account
    for account in compute_credits_acct_wk_df['ACCOUNT_NAME'].unique():
        account_data = compute_credits_acct_wk_df[compute_credits_acct_wk_df['ACCOUNT_NAME'] == account]
        compute_credits_acct_wk_fig.add_trace(go.Bar(
            x=account_data['USAGE_WEEK'],
            y=account_data['Compute Credits'],
            name=account
        ))
    
    # Update layout
    compute_credits_acct_wk_fig.update_layout(
        title='Weekly Compute Credits by Account',
        xaxis_title='Usage Week',
        yaxis_title='Compute Credits',
        barmode='group',
        height=500,
        showlegend=True
    )
    
    # Display the chart
    st.plotly_chart(compute_credits_acct_wk_fig, use_container_width=True)


    # Generated by Snowflake Copilot
    # Execute the query
    compute_credits_acct_dy_df = session.sql(compute_credits_by_acct_dy_sql).to_pandas()
    
    # Create bar chart
    compute_credits_acct_dy_fig = go.Figure()
    
    # Add bars for each account
    for account in compute_credits_acct_dy_df['ACCOUNT_NAME'].unique():
        account_data = compute_credits_acct_dy_df[compute_credits_acct_dy_df['ACCOUNT_NAME'] == account]
        compute_credits_acct_dy_fig.add_trace(go.Bar(
            x=account_data['USAGE_WEEK'],
            y=account_data['Compute Credits'],
            name=account
        ))
    
    # Update layout
    compute_credits_acct_dy_fig.update_layout(
        title='Daily Compute Credits by Account',
        xaxis_title='Usage Week',
        yaxis_title='Compute Credits',
        barmode='group',
        height=500,
        showlegend=True
    )
    
    # Display the chart
    st.plotly_chart(compute_credits_acct_dy_fig, use_container_width=True)

    # Generated by Snowflake Copilot
    # Execute the query
    pipe_credits_acct_mo_df = session.sql(pipe_credits_by_acct_mo_sql).to_pandas()
    
    # Create bar chart
    pipe_credits_acct_mo_fig = go.Figure()
    
    # Add bars for each account
    for account in pipe_credits_acct_mo_df['ACCOUNT_NAME'].unique():
        account_data = pipe_credits_acct_mo_df[pipe_credits_acct_mo_df['ACCOUNT_NAME'] == account]
        pipe_credits_acct_mo_fig.add_trace(go.Bar(
            x=account_data['USAGE_MONTH'],
            y=account_data['Credits Used'],
            name=account
        ))
    
    # Update layout
    pipe_credits_acct_mo_fig.update_layout(
        title='Monthly Pipe Credits by Account',
        xaxis_title='Usage Month',
        yaxis_title='Credits Used',
        barmode='group',
        height=500,
        showlegend=True
    )
    
    # Display the chart
    st.plotly_chart(pipe_credits_acct_mo_fig, use_container_width=True)

    
    # Generated by Snowflake Copilot
    # Execute the query
    pipe_credits_acct_wk_df = session.sql(pipe_credits_by_acct_wk_sql).to_pandas()
    
    # Create bar chart
    pipe_credits_acct_wk_fig = go.Figure()
    
    # Add bars for each account
    for account in pipe_credits_acct_wk_df['ACCOUNT_NAME'].unique():
        account_data = pipe_credits_acct_wk_df[pipe_credits_acct_wk_df['ACCOUNT_NAME'] == account]
        pipe_credits_acct_wk_fig.add_trace(go.Bar(
            x=account_data['USAGE_WEEK'],
            y=account_data['Credits Used'],
            name=account
        ))
    
    # Update layout
    pipe_credits_acct_wk_fig.update_layout(
        title='Weekly Pipe Credits by Account',
        xaxis_title='Usage Week',
        yaxis_title='Credits Used',
        barmode='group',
        height=500,
        showlegend=True
    )
    
    # Display the chart
    st.plotly_chart(pipe_credits_acct_wk_fig, use_container_width=True)

    # Generated by Snowflake Copilot
    # Execute the query
    pipe_credits_acct_dy_df = session.sql(pipe_credits_by_acct_dy_sql).to_pandas()
    
    # Create bar chart
    pipe_credits_acct_dy_fig = go.Figure()
    
    # Add bars for each account
    for account in pipe_credits_acct_dy_df['ACCOUNT_NAME'].unique():
        account_data = pipe_credits_acct_dy_df[pipe_credits_acct_dy_df['ACCOUNT_NAME'] == account]
        pipe_credits_acct_dy_fig.add_trace(go.Bar(
            x=account_data['USAGE_DAY'],
            y=account_data['Credits Used'],
            name=account
        ))
    
    # Update layout
    pipe_credits_acct_dy_fig.update_layout(
        title='Daily Pipe Credits by Account',
        xaxis_title='Usage Day',
        yaxis_title='Credits Used',
        barmode='group',
        height=500,
        showlegend=True
    )
    
    # Display the chart
    st.plotly_chart(pipe_credits_acct_dy_fig, use_container_width=True)


    # Generated by Snowflake Copilot
    # Execute the query
    db_storage_acct_mo_df = session.sql(db_storage_by_acct_mo_sql).to_pandas()
    
    # Create bar chart
    db_storage_acct_mo_fig = go.Figure()
    
    # Add bars for each account
    for account in db_storage_acct_mo_df['ACCOUNT_NAME'].unique():
        account_data = db_storage_acct_mo_df[db_storage_acct_mo_df['ACCOUNT_NAME'] == account]
        db_storage_acct_mo_fig.add_trace(go.Bar(
            x=account_data['USAGE_MONTH'],
            y=account_data['Avg DB TB'],
            name=account
        ))
    
    # Update layout
    db_storage_acct_mo_fig.update_layout(
        title='Monthly Average Database Storage (TB) by Account',
        xaxis_title='Usage Month',
        yaxis_title='Average Database Storage (TB)',
        barmode='group',
        height=500,
        showlegend=True
    )
    
    # Display the chart
    st.plotly_chart(db_storage_acct_mo_fig, use_container_width=True)

    # Generated by Snowflake Copilot
    # Execute the query
    db_storage_acct_wk_df = session.sql(db_storage_by_acct_wk_sql).to_pandas()
    
    # Create bar chart
    db_storage_acct_wk_fig = go.Figure()
    
    # Add bars for each account
    for account in db_storage_acct_wk_df['ACCOUNT_NAME'].unique():
        account_data = db_storage_acct_wk_df[db_storage_acct_wk_df['ACCOUNT_NAME'] == account]
        db_storage_acct_wk_fig.add_trace(go.Bar(
            x=account_data['USAGE_WEEK'],
            y=account_data['Avg DB TB'],
            name=account
        ))
    
    # Update layout
    db_storage_acct_wk_fig.update_layout(
        title='Weekly Average Database Storage (TB) by Account',
        xaxis_title='Usage Week', 
        yaxis_title='Average Database Storage (TB)',
        barmode='group',
        height=500,
        showlegend=True
    )
    
    # Display the chart
    st.plotly_chart(db_storage_acct_wk_fig, use_container_width=True)


    # Generated by Snowflake Copilot
    # Execute the query
    db_storage_acct_dy_df = session.sql(db_storage_by_acct_dy_sql).to_pandas()
    
    # Create bar chart
    db_storage_acct_dy_fig = go.Figure()
    
    # Add bars for each account
    for account in db_storage_acct_dy_df['ACCOUNT_NAME'].unique():
        account_data = db_storage_acct_dy_df[db_storage_acct_dy_df['ACCOUNT_NAME'] == account]
        db_storage_acct_dy_fig.add_trace(go.Bar(
            x=account_data['USAGE_DAY'], 
            y=account_data['Avg DB TB'],
            name=account
        ))
    
    # Update layout
    db_storage_acct_dy_fig.update_layout(
        title='Daily Average Database Storage (TB) by Account',
        xaxis_title='Usage Day',
        yaxis_title='Average Database Storage (TB)',
        barmode='group',
        height=500,
        showlegend=True
    )
    
    # Display the chart
    st.plotly_chart(db_storage_acct_dy_fig, use_container_width=True)

    
