# Generated by Snowflake Copilot
# Import python packages
import streamlit as st
import plotly
from snowflake.snowpark.context import get_active_session
# Import required packages
import plotly.graph_objects as go
import pandas as pd

# import app pages
# from sql.org_billable_credits import org_billable_usage

from plotly.subplots import make_subplots
session = get_active_session()

def org_usage_history_by_object():
    # Generated by Snowflake Copilot
    # Get account names
    acct_name_sql = """
    SELECT DISTINCT account_name 
    FROM HUB_DB.HUB_CONS_SC.WAREHOUSE_METERING_HISTORY_ALL
    ORDER BY account_name;
    """
    
    # Get account names into a list
    acct_df = session.sql(acct_name_sql).to_pandas()
    acct_list = acct_df['ACCOUNT_NAME'].tolist()
    acct_list.insert(0, 'ALL') # Add ALL option at beginning
    
    # Add multi-select dropdown
    selected_accts = st.multiselect(
        'Select Accounts',
        options=acct_list,
        default=['ALL']
    )
    
    # Handle ALL selection logic
    if 'ALL' in selected_accts:
        selected_acct_str = "'ALL'"
    else:
        selected_acct_str = "'" + "','".join(selected_accts) + "'"
    
    # Modify SQL queries to use selected accounts
    # Example modification for compute_credits_by_wh_mo_sql:


    compute_credits_by_wh_mo_sql = f"""
    WITH query_details AS
    (
    SELECT
    convert_timezone('America/Chicago',current_timestamp()) AS local_cts,
    convert_timezone('America/Chicago',start_time) AS local_start_time,
    DATE_TRUNC('month', local_start_time)::DATE usage_month
    ,warehouse_name
    ,credits_used_compute
    ,credits_used_cloud_services
    FROM HUB_DB.HUB_CONS_SC.WAREHOUSE_METERING_HISTORY_ALL
    WHERE local_start_time BETWEEN date_trunc('month', dateadd('month',-6,local_cts)) AND local_cts
    AND (account_name IN ({selected_acct_str}) or 'ALL' IN ({selected_acct_str}))
    )
    SELECT usage_month, warehouse_name
    ,ROUND(SUM(credits_used_compute),0) AS "Compute Credits"
    ,ROUND(SUM(credits_used_cloud_services),0) "Credits Used Cloud Svcs"
    ,CASE WHEN "Credits Used Cloud Svcs" - (SUM(credits_used_compute) / 10) > 0
    THEN "Credits Used Cloud Svcs" - ROUND((SUM(credits_used_compute) / 10)) ELSE 0 END AS "Cloud
    Services Credits Adj"
    FROM query_details
    GROUP BY 1,2
    ORDER BY 1,2;"""

    compute_credits_by_wh_wk_sql = f"""WITH query_details AS
    (
    SELECT
    convert_timezone('America/Chicago',current_timestamp()) AS local_cts,
    convert_timezone('America/Chicago',start_time) AS local_start_time,
    DATE_TRUNC('week', local_start_time)::DATE usage_week
    ,warehouse_name
    ,credits_used_compute
    ,credits_used_cloud_services
    FROM HUB_DB.HUB_CONS_SC.WAREHOUSE_METERING_HISTORY_ALL
    WHERE local_start_time BETWEEN date_trunc('week', dateadd('week',-27,local_cts)) AND local_cts
    AND (account_name IN ({selected_acct_str}) or 'ALL' IN ({selected_acct_str}))
    )
    SELECT usage_week, warehouse_name
    ,ROUND(SUM(credits_used_compute),0) AS "Compute Credits"
    ,ROUND(SUM(credits_used_cloud_services),0) "Credits Used Cloud Svcs"
    ,CASE WHEN "Credits Used Cloud Svcs" - (SUM(credits_used_compute) / 10) > 0
    THEN "Credits Used Cloud Svcs" - ROUND((SUM(credits_used_compute) / 10)) ELSE 0 END AS "Cloud
    Services Credits Adj"
    FROM query_details
    GROUP BY 1,2
    ORDER BY 1,2;"""

    compute_credits_by_wh_dy_sql = f"""
    WITH query_details AS
    (
    SELECT
    convert_timezone('America/Los_Angeles',current_timestamp()) AS local_cts,
    convert_timezone('America/Los_Angeles',start_time) AS local_start_time,
    convert_timezone('America/Los_Angeles',date_trunc('day', dateadd('day',-30,current_timestamp))) AS
    local_begin_date,
    DATE_TRUNC('day', local_start_time)::DATE usage_day
    ,warehouse_name
    ,credits_used_compute
    ,credits_used_cloud_services
    FROM HUB_DB.HUB_CONS_SC.WAREHOUSE_METERING_HISTORY_ALL
    WHERE local_start_time BETWEEN local_begin_date AND local_cts AND (account_name IN ({selected_acct_str}) or 'ALL' IN ({selected_acct_str}))
    )
    SELECT usage_day, warehouse_name
    ,ROUND(SUM(credits_used_compute),0) AS "Compute Credits"
    ,ROUND(SUM(credits_used_cloud_services),0) "Credits Used Cloud Svcs"
    ,CASE WHEN "Credits Used Cloud Svcs" - (SUM(credits_used_compute) / 10) > 0
    THEN "Credits Used Cloud Svcs" - ROUND((SUM(credits_used_compute) / 10)) ELSE 0 END AS "Cloud
    Services Credits Adj"
    FROM query_details
    GROUP BY 1,2
    ORDER BY 1,2;"""

    pipe_credits_by_name_and_mo_sql = f"""
    WITH query_details AS
    (
    SELECT
    convert_timezone('America/Chicago',current_date()) AS local_cdate,
    convert_timezone('America/Chicago',START_TIME) AS local_usage_date,
    account_name,
    pipe_name,
    account_name || '-->' || pipe_name AS fq_pipe_name,
    START_TIME as usage_date,
    DATE_TRUNC('month', START_TIME)::DATE usage_month,
    credits_used,
    bytes_inserted,
    files_inserted
    FROM HUB_DB.HUB_CONS_SC.PIPE_USAGE_HISTORY_ALL
    WHERE local_usage_date BETWEEN date_trunc('month', dateadd('month',-6,local_cdate)) AND local_cdate AND
    (account_name IN ({selected_acct_str}) or 'ALL' IN ({selected_acct_str}))
    )
    SELECT
    usage_month,
    --pipe_name,
    fq_pipe_name,
    ROUND(SUM(credits_used),0) AS "Credits Used",
    ROUND(SUM(bytes_inserted ),0) AS "Bytes Inserted",
    ROUND(SUM(files_inserted ),0) AS "Files Inserted"
    FROM query_details
    GROUP BY ALL
    ORDER BY 1,2
    ;"""

    pipe_credits_by_name_and_wk_sql = f"""
    WITH query_details AS
    (
    SELECT
    convert_timezone('America/Chicago',current_date()) AS local_cdate,
    convert_timezone('America/Chicago',START_TIME) AS local_usage_date,
    account_name,
    account_name || '-->' || pipe_name AS fq_pipe_name,
    pipe_name,
    START_TIME as usage_date,
    DATE_TRUNC('week', START_TIME)::DATE usage_week,
    credits_used,
    bytes_inserted,
    files_inserted
    FROM HUB_DB.HUB_CONS_SC.PIPE_USAGE_HISTORY_ALL
    WHERE local_usage_date BETWEEN date_trunc('month', dateadd('month',-6,local_cdate)) AND local_cdate AND
    (account_name IN ({selected_acct_str}) or 'ALL' IN ({selected_acct_str}))
    )
    SELECT
    usage_week, fq_pipe_name,
    ROUND(SUM(credits_used),0) AS "Credits Used",
    ROUND(SUM(bytes_inserted ),0) AS "Bytes Inserted",
    ROUND(SUM(files_inserted ),0) AS "Files Inserted"
    FROM query_details
    GROUP BY ALL
    ORDER BY 1,2
    ;"""

    pipe_credits_by_name_and_dy_sql = f"""
    WITH query_details AS
    (
    SELECT
    convert_timezone('America/Chicago',current_date()) AS local_cdate,
    convert_timezone('America/Chicago',START_TIME) AS local_usage_date,
    account_name,
    account_name || '-->' || pipe_name AS fq_pipe_name,
    pipe_name,
    START_TIME as usage_date,
    DATE_TRUNC('day', START_TIME)::DATE usage_day,
    credits_used,
    bytes_inserted,
    files_inserted
    FROM HUB_DB.HUB_CONS_SC.PIPE_USAGE_HISTORY_ALL
    WHERE local_usage_date BETWEEN date_trunc('month', dateadd('month',-6,local_cdate)) AND
    local_cdate AND (account_name IN ({selected_acct_str}) or 'ALL' IN ({selected_acct_str}))
    )
    SELECT
    usage_day, fq_pipe_name,
    ROUND(SUM(credits_used),0) AS "Credits Used",
    ROUND(SUM(bytes_inserted ),0) AS "Bytes Inserted",
    ROUND(SUM(files_inserted ),0) AS "Files Inserted"
    FROM query_details
    GROUP BY ALL
    ORDER BY 1,2
    ;"""

    db_storage_by_db_mo_sql = f"""
    WITH query_details AS
    (
    -- This sums up for all databases within the usage date and account
    SELECT
    convert_timezone('America/Chicago',current_date()) AS local_cdate,
    convert_timezone('America/Chicago',usage_date) AS local_usage_date,
    account_name,
    database_name,
    usage_date,
    SUM(average_database_bytes ) AS total_db_bytes_per_day,
    SUM(average_failsafe_bytes ) AS total_fs_bytes_per_day
    FROM HUB_DB.HUB_CONS_SC.DATABASE_STORAGE_USAGE_HISTORY_ALL
    WHERE local_usage_date BETWEEN date_trunc('month', dateadd('month',-6,local_cdate)) AND
    local_cdate AND (account_name IN ({selected_acct_str}) or 'ALL' IN ({selected_acct_str}))
    GROUP BY usage_date, account_name ,database_name
    )
    -- Get the Average Daily per month and account
    SELECT
    DATE_TRUNC('month', usage_date)::DATE usage_month,
    --account_name,
    database_name,
    ROUND(AVG(total_db_bytes_per_day) / POWER(2, 40),2) AS "Avg DB TB",
    ROUND(AVG(total_fs_bytes_per_day) / POWER(2, 40),4) AS "Avg Failsafe TB"
    FROM query_details
    GROUP BY ALL
    ORDER BY 1,2,3
    ;"""

    db_storage_by_db_wk_sql = f"""
    WITH query_details AS
    (
    -- This sums up for all databases within the usage date and account
    SELECT
    convert_timezone('America/Chicago',current_date()) AS local_cdate,
    convert_timezone('America/Chicago',usage_date) AS local_usage_date,
    account_name,
    database_name,
    usage_date,
    SUM(average_database_bytes ) AS total_db_bytes_per_day,
    SUM(average_failsafe_bytes ) AS total_fs_bytes_per_day
    FROM HUB_DB.HUB_CONS_SC.DATABASE_STORAGE_USAGE_HISTORY_ALL
    WHERE local_usage_date BETWEEN date_trunc('month', dateadd('month',-6,local_cdate)) AND
    local_cdate AND (account_name IN ({selected_acct_str}) or 'ALL' IN ({selected_acct_str}))
    GROUP BY usage_date, account_name ,database_name
    )
    -- Get the Average Daily per month and account
    SELECT
    DATE_TRUNC('month', usage_date)::DATE usage_month,
    --account_name,
    database_name,
    ROUND(AVG(total_db_bytes_per_day) / POWER(2, 40),2) AS "Avg DB TB",
    ROUND(AVG(total_fs_bytes_per_day) / POWER(2, 40),4) AS "Avg Failsafe TB"
    FROM query_details
    GROUP BY ALL
    ORDER BY 1,2,3
    ;"""

    db_storage_by_db_dy_sql = f"""
    WITH query_details AS
    (
    -- This sums up for all databases within the usage date and account
    SELECT
    convert_timezone('America/Chicago',current_date()) AS local_cdate,
    convert_timezone('America/Chicago',usage_date) AS local_usage_date,
    account_name,
    database_name,
    usage_date,
    SUM(average_database_bytes ) AS total_db_bytes_per_day,
    SUM(average_failsafe_bytes ) AS total_fs_bytes_per_day
    FROM HUB_DB.HUB_CONS_SC.DATABASE_STORAGE_USAGE_HISTORY_ALL
    WHERE local_usage_date BETWEEN date_trunc('month', dateadd('month',-6,local_cdate)) AND
    local_cdate AND (account_name IN ({selected_acct_str}) or 'ALL' IN ({selected_acct_str}))
    GROUP BY usage_date, account_name ,database_name
    )
    -- Get the Average Daily per month and account
    SELECT
    DATE_TRUNC('week', usage_date)::DATE usage_week,
    --account_name,
    database_name,
    ROUND(AVG(total_db_bytes_per_day) / POWER(2, 40),2) AS "Avg DB TB",
    ROUND(AVG(total_fs_bytes_per_day) / POWER(2, 40),4) AS "Avg Failsafe TB"
    FROM query_details
    GROUP BY ALL
    ORDER BY 1,2,3
    ;"""
    
    
    # Generated by Snowflake Copilot
    # Execute the query
    wh_compute_df = session.sql(compute_credits_by_wh_mo_sql).to_pandas()
    
    # Create bar chart
    wh_compute_fig = go.Figure()
    
    # Add bars for each warehouse
    for warehouse in wh_compute_df['WAREHOUSE_NAME'].unique():
        warehouse_data = wh_compute_df[wh_compute_df['WAREHOUSE_NAME'] == warehouse]
        wh_compute_fig.add_trace(go.Bar(
            x=warehouse_data['USAGE_MONTH'],
            y=warehouse_data['Compute Credits'],
            name=warehouse
        ))
    
    # Update layout
    wh_compute_fig.update_layout(
        title='Monthly Compute Credit Usage by Warehouse',
        xaxis_title='Usage Month',
        yaxis_title='Compute Credits',
        barmode='group',
        height=500,
        showlegend=True
    )
    
    # Display the chart
    st.plotly_chart(wh_compute_fig, use_container_width=True)

    # Generated by Snowflake Copilot
    # Execute the query
    wh_compute_wk_df = session.sql(compute_credits_by_wh_wk_sql).to_pandas()
    
    # Create bar chart
    wh_compute_wk_fig = go.Figure()
    
    # Add bars for each warehouse
    for warehouse in wh_compute_wk_df['WAREHOUSE_NAME'].unique():
        warehouse_data = wh_compute_wk_df[wh_compute_wk_df['WAREHOUSE_NAME'] == warehouse]
        wh_compute_wk_fig.add_trace(go.Bar(
            x=warehouse_data['USAGE_WEEK'],
            y=warehouse_data['Compute Credits'],
            name=warehouse
        ))
    
    # Update layout
    wh_compute_wk_fig.update_layout(
        title='Weekly Compute Credit Usage by Warehouse',
        xaxis_title='Usage Week',
        yaxis_title='Compute Credits',
        barmode='group',
        height=500,
        showlegend=True
    )
    
    # Display the chart
    st.plotly_chart(wh_compute_wk_fig, use_container_width=True)

    # Generated by Snowflake Copilot
    # Execute the query
    wh_compute_dy_df = session.sql(compute_credits_by_wh_dy_sql).to_pandas()
    
    # Create bar chart
    wh_compute_dy_fig = go.Figure()
    
    # Add bars for each warehouse
    for warehouse in wh_compute_dy_df['WAREHOUSE_NAME'].unique():
        warehouse_data = wh_compute_dy_df[wh_compute_dy_df['WAREHOUSE_NAME'] == warehouse]
        wh_compute_dy_fig.add_trace(go.Bar(
            x=warehouse_data['USAGE_DAY'],
            y=warehouse_data['Compute Credits'],
            name=warehouse
        ))
    
    # Update layout
    wh_compute_dy_fig.update_layout(
        title='Daily Compute Credit Usage by Warehouse',
        xaxis_title='Usage Day', 
        yaxis_title='Compute Credits',
        barmode='group',
        height=500,
        showlegend=True
    )
    
    # Display the chart
    st.plotly_chart(wh_compute_dy_fig, use_container_width=True)

    # Generated by Snowflake Copilot
    # Execute the query
    pipe_credits_df = session.sql(pipe_credits_by_name_and_mo_sql).to_pandas()
    
    # Create bar chart
    pipe_credits_fig = go.Figure()
    
    # Add bars for each pipe
    for pipe in pipe_credits_df['FQ_PIPE_NAME'].unique():
        pipe_data = pipe_credits_df[pipe_credits_df['FQ_PIPE_NAME'] == pipe]
        pipe_credits_fig.add_trace(go.Bar(
            x=pipe_data['USAGE_MONTH'],
            y=pipe_data['Credits Used'],
            name=pipe
        ))
    
    # Update layout
    pipe_credits_fig.update_layout(
        title='Monthly Pipe Credit Usage by Pipe',
        xaxis_title='Usage Month',
        yaxis_title='Credits Used',
        barmode='group',
        height=500,
        showlegend=True
    )
    
    # Display the chart
    st.plotly_chart(pipe_credits_fig, use_container_width=True)

    # Generated by Snowflake Copilot
    # Execute the query
    pipe_credits_wk_df = session.sql(pipe_credits_by_name_and_wk_sql).to_pandas()
    
    # Create bar chart
    pipe_credits_wk_fig = go.Figure()
    
    # Add bars for each pipe
    for pipe in pipe_credits_wk_df['FQ_PIPE_NAME'].unique():
        pipe_data = pipe_credits_wk_df[pipe_credits_wk_df['FQ_PIPE_NAME'] == pipe]
        pipe_credits_wk_fig.add_trace(go.Bar(
            x=pipe_data['USAGE_WEEK'],
            y=pipe_data['Credits Used'],
            name=pipe
        ))
    
    # Update layout
    pipe_credits_wk_fig.update_layout(
        title='Weekly Pipe Credit Usage by Pipe',
        xaxis_title='Usage Week',
        yaxis_title='Credits Used',
        barmode='group',
        height=500,
        showlegend=True
    )
    
    # Display the chart
    st.plotly_chart(pipe_credits_wk_fig, use_container_width=True)

    # Generated by Snowflake Copilot
    # Execute the query
    pipe_credits_dy_df = session.sql(pipe_credits_by_name_and_dy_sql).to_pandas()
    
    # Create bar chart
    pipe_credits_dy_fig = go.Figure()
    
    # Add bars for each pipe
    for pipe in pipe_credits_dy_df['FQ_PIPE_NAME'].unique():
        pipe_data = pipe_credits_dy_df[pipe_credits_dy_df['FQ_PIPE_NAME'] == pipe]
        pipe_credits_dy_fig.add_trace(go.Bar(
            x=pipe_data['USAGE_DAY'],
            y=pipe_data['Credits Used'],
            name=pipe
        ))
    
    # Update layout
    pipe_credits_dy_fig.update_layout(
        title='Daily Pipe Credit Usage by Pipe',
        xaxis_title='Usage Day',
        yaxis_title='Credits Used', 
        barmode='group',
        height=500,
        showlegend=True
    )
    
    # Display the chart
    st.plotly_chart(pipe_credits_dy_fig, use_container_width=True)

    # Generated by Snowflake Copilot
    # Execute the query
    db_storage_df = session.sql(db_storage_by_db_mo_sql).to_pandas()
    
    # Create bar chart
    db_storage_fig = go.Figure()
    
    # Add bars for each database
    for database in db_storage_df['DATABASE_NAME'].unique():
        database_data = db_storage_df[db_storage_df['DATABASE_NAME'] == database]
        db_storage_fig.add_trace(go.Bar(
            x=database_data['USAGE_MONTH'],
            y=database_data['Avg DB TB'],
            name=database
        ))
    
    # Update layout
    db_storage_fig.update_layout(
        title='Monthly Database Storage Usage by Database',
        xaxis_title='Usage Month',
        yaxis_title='Average Storage (TB)',
        barmode='group',
        height=500,
        showlegend=True
    )
    
    # Display the chart
    st.plotly_chart(db_storage_fig, use_container_width=True)
    
    # Generated by Snowflake Copilot
    # Execute the query
    db_storage_wk_df = session.sql(db_storage_by_db_wk_sql).to_pandas()
    
    # Create bar chart
    db_storage_wk_fig = go.Figure()
    
    # Add bars for each database
    for database in db_storage_wk_df['DATABASE_NAME'].unique():
        database_data = db_storage_wk_df[db_storage_df['DATABASE_NAME'] == database]
        db_storage_wk_fig.add_trace(go.Bar(
            x=database_data['USAGE_MONTH'],
            y=database_data['Avg DB TB'],
            name=database
        ))
    
    # Update layout
    db_storage_wk_fig.update_layout(
        title='Weekly Database Storage Usage by Database',
        xaxis_title='Usage Month',
        yaxis_title='Average Storage (TB)',
        barmode='group',
        height=500,
        showlegend=True
    )
    
    # Display the chart
    st.plotly_chart(db_storage_wk_fig, use_container_width=True)

    # Generated by Snowflake Copilot
    # Execute the query
    db_storage_dy_df = session.sql(db_storage_by_db_dy_sql).to_pandas()
    
    # Create bar chart
    db_storage_dy_fig = go.Figure()
    
    # Add bars for each database
    for database in db_storage_dy_df['DATABASE_NAME'].unique():
        database_data = db_storage_dy_df[db_storage_dy_df['DATABASE_NAME'] == database]
        db_storage_dy_fig.add_trace(go.Bar(
            x=database_data['USAGE_WEEK'], 
            y=database_data['Avg DB TB'],
            name=database
        ))
    
    # Update layout
    db_storage_dy_fig.update_layout(
        title='Daily Database Storage Usage by Database',
        xaxis_title='Usage Week',
        yaxis_title='Average Storage (TB)',
        barmode='group',
        height=500,
        showlegend=True
    )
    
    # Display the chart
    st.plotly_chart(db_storage_dy_fig, use_container_width=True)









    
